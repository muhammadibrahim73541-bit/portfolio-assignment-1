{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8140532",
   "metadata": {},
   "source": [
    "# Part A: Manual SGD \n",
    "\n",
    "This notebook demonstrates the mechanics of stochastic gradient descent by manually computing the forward pass, loss, gradient, and parameter updates for a simple linear regression model.\n",
    "\n",
    "**Model:**\n",
    "\\[\n",
    "ŷ = x · w\n",
    "\\]\n",
    "\n",
    "The first three samples of the Swedish Auto Insurance dataset are used.\n",
    "No preprocessing is applied to observe raw gradient behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ec37ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X      Y\n",
      "0  108  392.5\n",
      "1   19   46.2\n",
      "2   13   15.7 \n",
      "X is Input Features and Y is Target Feature\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/Swedish_Auto_Insurance_dataset.csv\")\n",
    "data = data.iloc[:3]\n",
    "print(data, \"\\nX is Input Features and Y is Target Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7db45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a4629d0",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection\n",
    "\n",
    "- Initial weight \\( w_0 = 0.5 \\)\n",
    "- Learning rate \\( \\alpha = 0.0001 \\)\n",
    "\n",
    "A small learning rate is chosen due to the relatively large input values, ensuring stable gradient updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83230a",
   "metadata": {},
   "source": [
    "## Manual SGD Computation\n",
    "\n",
    "For each sample, the following steps are applied:\n",
    "\n",
    "1. Forward: ŷ = x · w\n",
    "2. Loss: L = (t - ŷ)²\n",
    "3. Gradient: ∂L/∂w = 2x(ŷ - t)\n",
    "4. Update: wnew = wold - α · (∂L/∂w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61c6c9",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Initial weight (w₀) = 0.5  \n",
    "Learning rate (α) = 0.0001  \n",
    "\n",
    "No preprocessing is applied since the goal is to observe raw SGD behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ed1d9",
   "metadata": {},
   "source": [
    "### Sample 1\n",
    "\n",
    "### Given:**\n",
    "- \\( Input: x = 108 \\)\n",
    "- \\( Tareget: t = 392.5 \\) \n",
    "- \\( w = 0.5 \\)\n",
    "\n",
    "### Forward Pass:\n",
    "\\\n",
    "ŷ = x · w\n",
    "\\\n",
    "ŷ = 108 * 0.5\n",
    "\\\n",
    "ŷ = 54\n",
    "\n",
    "\n",
    "### Loss:\n",
    "\\\n",
    "L = (t - ŷ)²\n",
    "\\\n",
    "L = (392.5 - 54)²\n",
    "\\\n",
    "L = 114582.25\n",
    "\n",
    "\n",
    "### Gradient:\n",
    "\\\n",
    "∂L/∂w = 2x(ŷ - t)\n",
    "\n",
    "\n",
    "**We have**\n",
    "| Variable | Value | Description |\n",
    "|----------|-------|-------------|\n",
    "| x | 108 | Input |\n",
    "| t | 392.5 | Target |\n",
    "| ŷ | 54 | Prediction (x · w = 108 × 0.5) |\n",
    "| L | 114582.25 | Loss = (t - ŷ)² |\n",
    "\n",
    "\n",
    "\n",
    "**Chain Rule Setup**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "\n",
    "\n",
    "**Step 1: Calculate ∂L/∂ŷ** (Using Power Rule)\n",
    "\n",
    "$$L = (t - \\hat{y})^2$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\hat{y}} = \\frac{\\partial}{\\partial \\hat{y}}(t - \\hat{y})^2$$\n",
    "\n",
    "$$= 2(t - \\hat{y}) \\cdot \\frac{\\partial}{\\partial \\hat{y}}(t - \\hat{y})$$\n",
    "\n",
    "$$= 2(t - \\hat{y}) \\cdot \\left[\\frac{\\partial t}{\\partial \\hat{y}} - \\frac{\\partial \\hat{y}}{\\partial \\hat{y}}\\right]$$\n",
    "\n",
    "$$= 2(t - \\hat{y}) \\cdot [0 - 1]$$\n",
    "\n",
    "$$= 2(t - \\hat{y})(-1)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial \\hat{y}} = -2(t - \\hat{y}) = 2(\\hat{y} - t)}$$\n",
    "\n",
    "\n",
    "\n",
    "**Step 2: Calculate ∂ŷ/∂w**\n",
    "\n",
    "$$\\hat{y} = x \\cdot w$$\n",
    "\n",
    "$$\\frac{\\partial \\hat{y}}{\\partial w} = \\frac{\\partial}{\\partial w}(x \\cdot w)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial \\hat{y}}{\\partial w} = x}$$\n",
    "\n",
    "\n",
    "\n",
    "**Step 3: Combine Using Chain Rule**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "$$= 2(\\hat{y} - t) \\cdot x$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = 2x(\\hat{y} - t)}$$\n",
    "\n",
    "\n",
    "**Step 4: Numerical Calculation**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = 2(108)(54 - 392.5)$$\n",
    "\n",
    "$$= (216)(-338.5)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = -73116}$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = -73116$$\n",
    "\n",
    "\n",
    "### Update: wnew = wold - α · (∂L/∂w)\n",
    "\\\n",
    "wnew = 0.5 - 0.0001 · (-73116)\n",
    "\\\n",
    "wnew = 7.3116\n",
    "\\\n",
    "wnew = 0.5 + 7.3116 = 7.8116\n",
    "\n",
    "\n",
    "**Explanation**\n",
    "\\\n",
    "Gradient was negative (-73116) \n",
    "\\\n",
    "Loss decreases as weight increases \n",
    "\\\n",
    "Update added 7.3116 \n",
    "\\\n",
    "Large step due to big gradient magnitude \n",
    "\\\n",
    "New weight increased \n",
    "\\\n",
    "From 0.5 → 7.8116 (makes sense: ŷ=54 was too small, need larger w to reach t=392.5) \n",
    "\n",
    "**Verification (Optional)**\n",
    "New prediction would be:\n",
    "$$\\hat{y}_{new} = x \\cdot w_{new} = 108 \\times 7.8116 = 843.6528$$\n",
    "\n",
    "This overshoots target (392.5), indicating learning rate might be too large, but mathematically the update is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f49be",
   "metadata": {},
   "source": [
    "### Sample 2\n",
    "\n",
    "### Given:\n",
    "- \\( Input: x = 19 \\)\n",
    "- \\( Target: t = 46.2 \\) \n",
    "- \\( w = 7.8116 \\) (carried from Sample 1)\n",
    "\n",
    "### Forward Pass:\n",
    "\\\n",
    "ŷ = x · w\n",
    "\\\n",
    "ŷ = 19 * 7.8116\n",
    "\\\n",
    "ŷ = 148.4204\n",
    "\n",
    "### Loss:\n",
    "\\\n",
    "L = (t - ŷ)²\n",
    "\\\n",
    "L = (46.2 - 148.4204)²\n",
    "\\\n",
    "L = (-102.2204)²\n",
    "\\\n",
    "L = 10449.0082\n",
    "\n",
    "### Gradient:\n",
    "\\\n",
    "∂L/∂w = 2x(ŷ - t)\n",
    "\n",
    "**We have**\n",
    "| Variable | Value | Description |\n",
    "|----------|-------|-------------|\n",
    "| x | 19 | Input |\n",
    "| t | 46.2 | Target |\n",
    "| ŷ | 148.4204 | Prediction (x · w = 19 × 7.8116) |\n",
    "| L | 10449.0082 | Loss = (t - ŷ)² |\n",
    "\n",
    "**Chain Rule Setup**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "**Step 1: Calculate ∂L/∂ŷ** (Using Power Rule)\n",
    "\n",
    "$$L = (t - \\hat{y})^2$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\hat{y}} = 2(t - \\hat{y}) \\cdot (-1) = 2(\\hat{y} - t)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - t)}$$\n",
    "\n",
    "**Step 2: Calculate ∂ŷ/∂w**\n",
    "\n",
    "$$\\hat{y} = x \\cdot w$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial \\hat{y}}{\\partial w} = x}$$\n",
    "\n",
    "**Step 3: Combine Using Chain Rule**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = 2(\\hat{y} - t) \\cdot x$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = 2x(\\hat{y} - t)}$$\n",
    "\n",
    "**Step 4: Numerical Calculation**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = 2(19)(148.4204 - 46.2)$$\n",
    "\n",
    "$$= (38)(102.2204)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = 3884.3752}$$\n",
    "\n",
    "### Update: wnew = wold - α · (∂L/∂w)\n",
    "\\\n",
    "wnew = 7.8116 - 0.0001 · (3884.3752)\n",
    "\\\n",
    "wnew = 7.8116 - 0.3884\n",
    "\\\n",
    "wnew = 7.4232\n",
    "\n",
    "**Explanation**\n",
    "\\\n",
    "Gradient was positive (3884.3752)\n",
    "\\\n",
    "Loss decreases as weight decreases\n",
    "\\\n",
    "Update subtracted 0.3884\n",
    "\\\n",
    "From 7.8116 → 7.4232 (makes sense: ŷ=148.42 was too large, need smaller w to reach t=46.2)\n",
    "\n",
    "---\n",
    "\n",
    "### Sample 3\n",
    "\n",
    "### Given:\n",
    "- \\( Input: x = 13 \\)\n",
    "- \\( Target: t = 15.7 \\) \n",
    "- \\( w = 7.4232 \\) (carried from Sample 2)\n",
    "\n",
    "### Forward Pass:\n",
    "\\\n",
    "ŷ = x · w\n",
    "\\\n",
    "ŷ = 13 * 7.4232\n",
    "\\\n",
    "ŷ = 96.5016\n",
    "\n",
    "### Loss:\n",
    "\\\n",
    "L = (t - ŷ)²\n",
    "\\\n",
    "L = (15.7 - 96.5016)²\n",
    "\\\n",
    "L = (-80.8016)²\n",
    "\\\n",
    "L = 6528.8986\n",
    "\n",
    "### Gradient:\n",
    "\\\n",
    "∂L/∂w = 2x(ŷ - t)\n",
    "\n",
    "**We have**\n",
    "| Variable | Value | Description |\n",
    "|----------|-------|-------------|\n",
    "| x | 13 | Input |\n",
    "| t | 15.7 | Target |\n",
    "| ŷ | 96.5016 | Prediction (x · w = 13 × 7.4232) |\n",
    "| L | 6528.8986 | Loss = (t - ŷ)² |\n",
    "\n",
    "**Chain Rule Setup**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "**Step 1: Calculate ∂L/∂ŷ** (Using Power Rule)\n",
    "\n",
    "$$L = (t - \\hat{y})^2$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\hat{y}} = 2(t - \\hat{y}) \\cdot (-1) = 2(\\hat{y} - t)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - t)}$$\n",
    "\n",
    "**Step 2: Calculate ∂ŷ/∂w**\n",
    "\n",
    "$$\\hat{y} = x \\cdot w$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial \\hat{y}}{\\partial w} = x}$$\n",
    "\n",
    "**Step 3: Combine Using Chain Rule**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = 2(\\hat{y} - t) \\cdot x$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = 2x(\\hat{y} - t)}$$\n",
    "\n",
    "**Step 4: Numerical Calculation**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = 2(13)(96.5016 - 15.7)$$\n",
    "\n",
    "$$= (26)(80.8016)$$\n",
    "\n",
    "$$\\boxed{\\frac{\\partial L}{\\partial w} = 2100.8416}$$\n",
    "\n",
    "### Update: wnew = wold - α · (∂L/∂w)\n",
    "\\\n",
    "wnew = 7.4232 - 0.0001 · (2100.8416)\n",
    "\\\n",
    "wnew = 7.4232 - 0.2101\n",
    "\\\n",
    "wnew = 7.2131\n",
    "\n",
    "**Explanation**\n",
    "\\\n",
    "Gradient was positive (2100.8416)\n",
    "\\\n",
    "Loss decreases as weight decreases\n",
    "\\\n",
    "Update subtracted 0.2101\n",
    "\\\n",
    "From 7.4232 → 7.2131 (makes sense: ŷ=96.50 was too large, need smaller w to reach t=15.7)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Sample | w (old) | x | ŷ | dL/dw | w (new) |\n",
    "|--------|---------|---|---|-------|---------|\n",
    "| 1 | 0.5 | 108 | 54 | -73116 | 7.8116 |\n",
    "| 2 | 7.8116 | 19 | 148.4204 | 3884.3752 | 7.4232 |\n",
    "| 3 | 7.4232 | 13 | 96.5016 | 2100.8416 | 7.2131 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
